# üìö Documentation d'Installation - Quiz Generator

## Table des mati√®res

1. [Pr√©requis](#pr√©requis)
2. [Installation d'Ollama](#installation-dollama)
3. [Configuration du Backend](#configuration-du-backend)
4. [Configuration du Frontend](#configuration-du-frontend)
5. [Exemple d'appel API vers Ollama](#exemple-dappel-api-vers-ollama)
6. [S√©curit√©](#s√©curit√©)
7. [D√©pannage](#d√©pannage)

---

## Pr√©requis

### Syst√®me
- **OS**: Ubuntu 20.04+ / macOS 12+ / Windows 10+ (avec WSL2)
- **RAM**: 8 GB minimum (16 GB recommand√© pour Ollama)
- **Disque**: 20 GB d'espace libre

### Logiciels requis
- **Python**: 3.11 ou sup√©rieur
- **Node.js**: 18.x ou sup√©rieur
- **PostgreSQL**: 14 ou sup√©rieur
- **Ollama**: Derni√®re version

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install python3.11 python3.11-venv nodejs npm postgresql tesseract-ocr poppler-utils

# macOS
brew install python@3.11 node postgresql tesseract poppler
```

---

## Installation d'Ollama

### 1. Installer Ollama

```bash
# Linux/macOS
curl -fsSL https://ollama.com/install.sh | sh
```

### 2. Cr√©er le mod√®le qcm-generator

```bash
# T√©l√©charger le mod√®le de base
ollama pull llama3.2:latest

# Cr√©er le mod√®le personnalis√©
cd docs
ollama create qcm-generator -f Modelfile
```

### 3. V√©rifier l'installation

```bash
ollama list
curl http://localhost:11434/api/tags
```

---

## Configuration du Backend

### 1. Environnement virtuel

```bash
cd backend
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Base de donn√©es PostgreSQL

```bash
sudo -u postgres psql
CREATE DATABASE quiz_generator;
CREATE USER quiz_user WITH PASSWORD 'password';
GRANT ALL PRIVILEGES ON DATABASE quiz_generator TO quiz_user;
\q
```

### 3. Variables d'environnement

```bash
cp .env.example .env
# √âditer .env avec vos param√®tres
```

### 4. Migrations et d√©marrage

```bash
python manage.py migrate
python manage.py createsuperuser
python manage.py runserver
```

---

## Configuration du Frontend

```bash
cd frontend
npm install
ng serve
```

Acc√®s: http://localhost:4200

---

## Exemple d'appel API vers Ollama

```python
import requests
import json

payload = {
    "model": "qcm-generator",
    "messages": [{
        "role": "user",
        "content": json.dumps({
            "text": "Le machine learning est une branche de l'IA...",
            "nb_questions": 5,
            "difficulty": "intermediaire"
        })
    }],
    "stream": False
}

response = requests.post("http://localhost:11434/api/chat", json=payload)
result = response.json()
questions = json.loads(result["message"]["content"])
```

---

## S√©curit√©

- JWT Authentication avec refresh tokens
- CORS configur√© pour le frontend
- Validation des fichiers upload√©s
- Protection CSRF activ√©e

---

## D√©pannage

### Ollama ne r√©pond pas
```bash
curl http://localhost:11434/api/tags
ollama serve
```

### Erreur PostgreSQL
```bash
sudo systemctl status postgresql
```
